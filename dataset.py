
import os
import h5py
import torch
import numpy as np
import pandas as pd
from torch.utils.data import Dataset, DataLoader
import torchvision.transforms as transforms

# âœ… Update dataset paths (your real data)
IMG_DIR = r"D:\Datasets\Landslide4Sense\img"
MASK_DIR = r"D:\Datasets\Landslide4Sense\mask"
CSV_DIR = r"D:\rockfall_ai\rockfall_ai\data\clean_dataset"  # CSVs generated by prepare_dataset.py


class SegmentationDataset(Dataset):
    def __init__(self, csv_file, img_dir=IMG_DIR, mask_dir=MASK_DIR, img_size=224, augment=False):
        self.df = pd.read_csv(csv_file)
        self.img_dir = img_dir
        self.mask_dir = mask_dir
        self.img_size = img_size
        self.augment = augment

        self.transform_img = transforms.Compose([
            transforms.ToTensor(),
            transforms.Resize((img_size, img_size))
        ])
        self.transform_mask = transforms.Compose([
            transforms.ToTensor(),
            transforms.Resize((img_size, img_size))
        ])

    def __len__(self):
        return len(self.df)

    def __getitem__(self, idx):
        row = self.df.iloc[idx]
        img_path = os.path.join(self.img_dir, row['filename'])
        mask_path = os.path.join(self.mask_dir, row['mask'])

        # Load from .h5 files
        with h5py.File(img_path, "r") as f:
            image = np.array(f["img"])
        with h5py.File(mask_path, "r") as f:
            mask = np.array(f["mask"])

        # Normalize
        image = image.astype(np.float32) / 255.0
        mask = mask.astype(np.float32)

        # Add channels if grayscale
        if image.ndim == 2:
            image = np.expand_dims(image, axis=-1)
        if mask.ndim == 2:
            mask = np.expand_dims(mask, axis=-1)

        # Apply transforms
        image = self.transform_img(image)
        mask = self.transform_mask(mask)

        # Simple augmentation (flip)
        if self.augment and torch.rand(1) > 0.5:
            image = torch.flip(image, dims=[2])
            mask = torch.flip(mask, dims=[2])

        return image, mask


def get_dataloaders(batch_size=2, img_size=224):
    train_dataset = SegmentationDataset(os.path.join(CSV_DIR, "train.csv"), IMG_DIR, MASK_DIR, img_size, augment=True)
    val_dataset   = SegmentationDataset(os.path.join(CSV_DIR, "val.csv"), IMG_DIR, MASK_DIR, img_size)
    test_dataset  = SegmentationDataset(os.path.join(CSV_DIR, "test.csv"), IMG_DIR, MASK_DIR, img_size)

    loaders = {
        "train": DataLoader(train_dataset, batch_size=batch_size, shuffle=True),
        "val":   DataLoader(val_dataset, batch_size=batch_size, shuffle=False),
        "test":  DataLoader(test_dataset, batch_size=batch_size, shuffle=False),
    }
    return loaders
